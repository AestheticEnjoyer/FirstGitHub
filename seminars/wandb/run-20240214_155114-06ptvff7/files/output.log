dL/dw = tensor([-11.9459])
dL/db = tensor([-43.6487])
loss =  239.05943
loss =  142.81453
loss =  111.95839
loss =  101.19949
loss =  96.64512
loss =  94.0329
loss =  92.0543
loss =  90.3068
loss =  88.66582
loss =  87.09198
loss =  85.57217
loss =  84.101326
loss =  82.676834
loss =  81.29697
loss =  79.96023
loss =  78.66525
loss =  77.41069
loss =  76.195305
loss =  75.01786
loss =  73.8772
loss =  72.772125
loss =  71.70157
loss =  70.66444
loss =  69.659676
loss =  68.686295
loss =  67.74331
loss =  66.829735
loss =  65.94472
loss =  65.08732
loss =  64.25669
loss =  63.452
loss =  62.672424
loss =  61.917194
loss =  61.185543
loss =  60.476734
loss =  59.79005
loss =  59.12481
loss =  58.480343
loss =  57.85599
loss =  57.251144
loss =  56.665165
loss =  56.097485
loss =  55.54754
loss =  55.01475
loss =  54.498604
loss =  53.998577
loss =  53.514153
loss =  53.04485
loss =  52.59021
loss =  52.149765
loss =  51.72306
loss =  51.309677
loss =  50.909218
loss =  50.52124
loss =  50.145397
loss =  49.781273
loss =  49.42852
loss =  49.08679
loss =  48.755726
loss =  48.43499
loss =  48.12427
loss =  47.823257
loss =  47.531635
loss =  47.24912
loss =  46.975433
loss =  46.710278
loss =  46.453415
loss =  46.204567
loss =  45.96349
loss =  45.729935
loss =  45.50367
loss =  45.284473
loss =  45.072132
loss =  44.866405
loss =  44.667103
loss =  44.474026
loss =  44.286976
loss =  44.105762
loss =  43.93021
loss =  43.76014
loss =  43.59538
loss =  43.435757
loss =  43.281124
loss =  43.13132
loss =  42.98619
loss =  42.845592
loss =  42.70938
loss =  42.57743
loss =  42.44959
loss =  42.325745
loss =  42.205765
loss =  42.089535
loss =  41.976936
loss =  41.867847
loss =  41.762165
loss =  41.659786
loss =  41.560593
loss =  41.46451
loss =  41.371418
loss =  41.28124
loss =  41.193874
loss =  41.109234
loss =  41.02724
loss =  40.947803
loss =  40.870846
loss =  40.796295
loss =  40.724064
loss =  40.6541
loss =  40.586308
loss =  40.52064
loss =  40.45702
loss =  40.395393
loss =  40.335674
loss =  40.27784
loss =  40.221794
loss =  40.167507
loss =  40.114914
loss =  40.06396
loss =  40.0146
loss =  39.966778
loss =  39.920452
loss =  39.875572
loss =  39.83209
loss =  39.789967
loss =  39.749157
loss =  39.70963
loss =  39.67133
loss =  39.634228
loss =  39.598286
loss =  39.56347
loss =  39.529728
loss =  39.497047
loss =  39.465385
loss =  39.434715
loss =  39.405
loss =  39.37621
loss =  39.34832
loss =  39.321304
loss =  39.29514
loss =  39.269775
loss =  39.24521
loss =  39.22141
loss =  39.198353
loss =  39.17602
loss =  39.154385
loss =  39.133423
loss =  39.113113
loss =  39.093437
loss =  39.07437
loss =  39.055912
loss =  39.038025
loss =  39.020695
loss =  39.003906
loss =  38.98764
loss =  38.97188
loss =  38.956623
loss =  38.941826
loss =  38.9275
loss =  38.913624
loss =  38.900177
loss =  38.887154
loss =  38.87454
loss =  38.862312
loss =  38.850468
loss =  38.838993
loss =  38.827877
loss =  38.817116
loss =  38.806675
loss =  38.796574
loss =  38.78678
loss =  38.777298
loss =  38.768105
loss =  38.7592
loss =  38.75058
loss =  38.742226
loss =  38.734123
loss =  38.726288
loss =  38.71869
loss =  38.71133
loss =  38.704197
loss =  38.697292
loss =  38.690605
loss =  38.684116
loss =  38.677837
loss =  38.671757
loss =  38.665863
loss =  38.66015
loss =  38.654617
loss =  38.64926
loss =  38.644066
loss =  38.639038
loss =  38.634163
loss =  38.629448
loss =  38.624874
loss =  38.620445
loss =  38.61615
loss =  38.611988
loss =  38.60796
loss =  38.60406
loss =  38.60028
Sample:
tensor([[0.6106, 0.0416, 0.6225, 0.8074, 0.8857],
        [0.4611, 0.9960, 0.0168, 0.6195, 0.6114],
        [0.2185, 0.7637, 0.9111, 0.4889, 0.6469],
        [0.5787, 0.2839, 0.8734, 0.0186, 0.1881]])
Target:
tensor([0.2002, 0.1352, 0.5188, 0.5955], dtype=torch.float64)
wandb: Appending key for api.wandb.ai to your netrc file: C:\Users\Алексей\.netrc